{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f79baf9",
   "metadata": {},
   "source": [
    "# ADS 509 Sentiment Assignment\n",
    "\n",
    "This notebook holds the Sentiment Assignment for Module 6 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In a previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we apply sentiment analysis to those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d096b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b555ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import statements you need here\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "923b5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `data_location` to the location of the folder on your machine.\n",
    "data_location = \"/Users/clairebentzen/Desktop/MDAS/ADS 509 - Applied Text Mining/Module 2/Assignment2.1/M1 Results/\"\n",
    "\n",
    "# These subfolders should still work if you correctly stored the \n",
    "# data from the Module 1 assignment\n",
    "twitter_folder = \"twitter/\"\n",
    "lyrics_folder = \"lyrics/\"\n",
    "\n",
    "# Specify artist_files for twitter data\n",
    "artist_files = {'cher':'cher_followers_data.txt',\n",
    "                'robyn':'robynkonichiwa_followers_data.txt'}\n",
    "\n",
    "positive_words_file = \"positive-words.txt\"\n",
    "negative_words_file = \"negative-words.txt\"\n",
    "tidy_text_file = \"tidytext_sentiments.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bf93e",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A Pandas data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37d70801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the lyrics data\n",
    "# Specify pathway to lyrics folder\n",
    "lyrics_path = data_location + lyrics_folder\n",
    "\n",
    "# Create a dataframe to store results\n",
    "lyrics_data = pd.DataFrame(columns=['artist', 'song', 'lyrics'])\n",
    "\n",
    "# Iterate through each file in the lyrics folder\n",
    "for artist in os.listdir(lyrics_path):\n",
    "    artist_path = os.path.join(lyrics_path, artist)\n",
    "    \n",
    "    # Iterate through each file in the artist folders\n",
    "    for song in os.listdir(artist_path):\n",
    "        song_path = os.path.join(artist_path, song)\n",
    "        rem_prefix = song.removeprefix(f'{artist}_')\n",
    "        song_title = rem_prefix.removesuffix('.txt')\n",
    "\n",
    "        # Open and read the contents of the file (song)\n",
    "        with open(song_path, 'r') as file:\n",
    "            contents = file.read()\n",
    "            # Prepare data to add to dataframe\n",
    "            data = {'artist': artist, 'song': song_title, 'lyrics': contents}\n",
    "            # The df.append() function is deprecated, so we will ignore warnings here\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter('ignore')\n",
    "                # Append row of data to lyrics_df\n",
    "                lyrics_data = lyrics_data.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d9b919e-644d-4fc3-ac3e-30fb5f3f4de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robyn</td>\n",
       "      <td>includemeout</td>\n",
       "      <td>\"Include Me Out\"\\n\\n\\n\\nIt is really very simp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>robyn</td>\n",
       "      <td>electric</td>\n",
       "      <td>\"Electric\"\\n\\n\\n\\nElectric...\\n\\nIt's electric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>robyn</td>\n",
       "      <td>beach2k20</td>\n",
       "      <td>\"Beach 2K20\"\\n\\n\\n\\n(So you wanna go out?\\nHow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>robyn</td>\n",
       "      <td>lovekills</td>\n",
       "      <td>\"Love Kills\"\\n\\n\\n\\nIf you're looking for love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>robyn</td>\n",
       "      <td>timemachine</td>\n",
       "      <td>\"Time Machine\"\\n\\n\\n\\nHey, what did I do?\\nCan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist          song                                             lyrics\n",
       "0  robyn  includemeout  \"Include Me Out\"\\n\\n\\n\\nIt is really very simp...\n",
       "1  robyn      electric  \"Electric\"\\n\\n\\n\\nElectric...\\n\\nIt's electric...\n",
       "2  robyn     beach2k20  \"Beach 2K20\"\\n\\n\\n\\n(So you wanna go out?\\nHow...\n",
       "3  robyn     lovekills  \"Love Kills\"\\n\\n\\n\\nIf you're looking for love...\n",
       "4  robyn   timemachine  \"Time Machine\"\\n\\n\\n\\nHey, what did I do?\\nCan..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View lyrics_data dataframe\n",
    "lyrics_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "debcac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the twitter data\n",
    "# Read cher twitter data\n",
    "twitter_data = pd.read_csv(data_location + twitter_folder + artist_files['cher'],\n",
    "                           sep=\"\\t\",\n",
    "                           quoting=3)\n",
    "\n",
    "twitter_data['artist'] = \"cher\"\n",
    "\n",
    "# Read robyn twitter data\n",
    "twitter_data_2 = pd.read_csv(data_location + twitter_folder + artist_files['robyn'],\n",
    "                             sep=\"\\t\",\n",
    "                             quoting=3)\n",
    "twitter_data_2['artist'] = \"robyn\"\n",
    "\n",
    "# Concat twitter dataframes\n",
    "twitter_data = pd.concat([\n",
    "    twitter_data,twitter_data_2])\n",
    "    \n",
    "del(twitter_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56f45902-9613-47ef-9c2a-bb849810fa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only artist and description columns\n",
    "twitter_data = twitter_data[['description', 'artist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af9e7a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a+</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abound</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abounds</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abundance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abundant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15128</th>\n",
       "      <td>win</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15129</th>\n",
       "      <td>winner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15130</th>\n",
       "      <td>winners</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15131</th>\n",
       "      <td>winning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15132</th>\n",
       "      <td>worthy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21922 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  score\n",
       "0             a+      1\n",
       "1         abound      1\n",
       "2        abounds      1\n",
       "3      abundance      1\n",
       "4       abundant      1\n",
       "...          ...    ...\n",
       "15128        win      1\n",
       "15129     winner      1\n",
       "15130    winners      1\n",
       "15131    winning      1\n",
       "15132     worthy      1\n",
       "\n",
       "[21922 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the positive and negative words and the\n",
    "# tidytext sentiment. Store these so that the positive\n",
    "# words are associated with a score of +1 and negative words\n",
    "# are associated with a score of -1. You can use a dataframe or a \n",
    "# dictionary for this.\n",
    "\n",
    "# Read positive words and add score column\n",
    "pos_words = pd.read_csv('positive-words.txt', delimiter='\\t', skiprows=35, header=None)\n",
    "pos_words['score'] = 1\n",
    "pos_words.columns.values[0] = 'word'\n",
    "\n",
    "# Read negative words and add score column\n",
    "neg_words = pd.read_csv('negative-words.txt', delimiter='\\t', skiprows=35, header=None)\n",
    "neg_words['score'] = -1\n",
    "neg_words.columns.values[0] = 'word'\n",
    "\n",
    "# Read tidytext sentiment\n",
    "tidytext = pd.read_csv('tidytext_sentiments.txt', delimiter='\\t')\n",
    "tidytext.drop(columns='lexicon', inplace=True)\n",
    "# Replace sentiment with -1 and 1\n",
    "tidytext['score'] = tidytext['sentiment'].apply(lambda x: -1 if x == 'negative' else 1)\n",
    "tidytext.drop(columns='sentiment', inplace=True)\n",
    "\n",
    "# Combine dataframes\n",
    "sentiment_scores = pd.concat([pos_words, neg_words, tidytext])\n",
    "sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b1f6f47-5b75-441f-9d1f-3ae881282adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>cher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>𝙿𝚛𝚘𝚞𝚍 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛 𝚘𝚏 𝚖𝚎𝚜𝚜𝚢 𝚋𝚞𝚗𝚜 &amp; 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜</td>\n",
       "      <td>cher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163㎝／愛かっぷ💜26歳🍒 工〇好きな女の子💓 フォローしてくれたらDMします🧡</td>\n",
       "      <td>cher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>csu</td>\n",
       "      <td>cher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Writer @Washinformer @SpelmanCollege alumna #D...</td>\n",
       "      <td>cher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description artist\n",
       "0                                                NaN   cher\n",
       "1           𝙿𝚛𝚘𝚞𝚍 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛 𝚘𝚏 𝚖𝚎𝚜𝚜𝚢 𝚋𝚞𝚗𝚜 & 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜   cher\n",
       "2          163㎝／愛かっぷ💜26歳🍒 工〇好きな女の子💓 フォローしてくれたらDMします🧡   cher\n",
       "3                                                csu   cher\n",
       "4  Writer @Washinformer @SpelmanCollege alumna #D...   cher"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View twitter_data dataframe\n",
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f3b12",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Songs\n",
    "\n",
    "In this section, score the sentiment for all the songs for both artists in your data set. Score the sentiment by manually calculating the sentiment using the combined lexicons provided in this repository. \n",
    "\n",
    "After you have calculated these sentiments, answer the questions at the end of this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664f8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8334f4",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "Q: Overall, which artist has the higher average sentiment per song? \n",
    "\n",
    "A: <!-- Your answer here -->\n",
    "\n",
    "---\n",
    "\n",
    "Q: For your first artist, what are the three songs that have the highest and lowest sentiments? Print the lyrics of those songs to the screen. What do you think is driving the sentiment score? \n",
    "\n",
    "A: <!-- Your answer here -->\n",
    "\n",
    "---\n",
    "\n",
    "Q: For your second artist, what are the three songs that have the highest and lowest sentiments? Print the lyrics of those songs to the screen. What do you think is driving the sentiment score? \n",
    "\n",
    "A: <!-- Your answer here -->\n",
    "\n",
    "---\n",
    "\n",
    "Q: Plot the distributions of the sentiment scores for both artists. You can use `seaborn` to plot densities or plot histograms in matplotlib.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe644d",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Twitter Descriptions\n",
    "\n",
    "In this section, define two sets of emojis you designate as positive and negative. Make sure to have at least 10 emojis per set. You can learn about the most popular emojis on Twitter at [the emojitracker](https://emojitracker.com/). \n",
    "\n",
    "Associate your positive emojis with a score of +1, negative with -1. Score the average sentiment of your two artists based on the Twitter descriptions of their followers. The average sentiment can just be the total score divided by number of followers. You do not need to calculate sentiment on non-emoji content for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb92eb93",
   "metadata": {},
   "source": [
    "Q: What is the average sentiment of your two artists? \n",
    "\n",
    "A: <!-- Your answer here --> \n",
    "\n",
    "---\n",
    "\n",
    "Q: Which positive emoji is the most popular for each artist? Which negative emoji? \n",
    "\n",
    "A: <!-- Your answer here --> \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
